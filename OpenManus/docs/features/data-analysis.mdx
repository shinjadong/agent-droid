# 데이터 분석 (Data Analysis)

OpenManus는 Python의 강력한 데이터 분석 라이브러리들을 활용하여 복잡한 데이터 분석 작업을 자동화할 수 있습니다. 데이터 수집부터 정제, 분석, 시각화까지 전 과정을 에이전트가 처리합니다.

## 개요

데이터 분석 기능의 핵심 요소:

- **자동화된 데이터 처리**: pandas, numpy를 통한 데이터 조작
- **통계 분석**: scipy, statsmodels를 활용한 고급 분석
- **데이터 시각화**: matplotlib, seaborn, plotly로 차트 생성
- **머신러닝**: scikit-learn을 통한 모델 학습 및 예측
- **대용량 데이터**: 효율적인 메모리 관리와 청크 처리

:::info[📖 데이터 분석]

**정의**: 데이터 분석은 원시 데이터를 수집, 정제, 변환하여 의미 있는 인사이트를 도출하는 과정입니다.

**쉬운 비유**:
데이터 분석은 금광에서 금을 캐는 것과 같습니다. 흙 더미(원시 데이터)를 파내고, 불순물을 제거하고(데이터 정제), 금을 분리하여(분석), 가치 있는 금괴(인사이트)를 만들어내는 과정입니다.

**메커니즘**:
```
┌─────────────────────────────────────┐
│ 1. 데이터 수집 (Collection)          │
│    - CSV, Excel, 데이터베이스       │
│    - API, 웹 스크래핑               │
└─────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────┐
│ 2. 데이터 정제 (Cleaning)            │
│    - 결측값 처리                    │
│    - 이상치 제거                    │
│    - 데이터 타입 변환               │
└─────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────┐
│ 3. 탐색적 분석 (EDA)                │
│    - 기술 통계                      │
│    - 상관관계 분석                  │
│    - 시각화                        │
└─────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────┐
│ 4. 모델링 & 인사이트 (Insights)      │
│    - 패턴 발견                      │
│    - 예측 모델                      │
│    - 의사결정 지원                  │
└─────────────────────────────────────┘
```

**존재 이유**:
1. **의사결정**: 데이터 기반의 합리적 결정
2. **문제 해결**: 숨겨진 패턴과 문제점 발견
3. **예측**: 미래 트렌드 및 결과 예측
4. **최적화**: 프로세스 및 리소스 효율화

:::

## 기본 사용법

### CSV 파일 분석

```python
from app.agent.data_analysis import DataAnalysis

agent = await DataAnalysis.create()

# CSV 파일 로드 및 기본 분석
await agent.run("""
sales_data.csv 파일을 읽어서:
1. 기본 통계 정보 확인
2. 결측값 확인
3. 각 열의 데이터 타입 확인
""")

# 특정 조건으로 필터링
await agent.run("""
sales_data.csv에서:
- 매출액이 1000 이상인 데이터만 추출
- 날짜별로 그룹화
- 평균 매출 계산
결과를 filtered_sales.csv로 저장
""")
```

### Excel 파일 처리

```python
await agent.run("""
report.xlsx 파일을:
1. 모든 시트 읽기
2. 각 시트의 데이터 요약
3. 시트별로 PDF 리포트 생성
""")
```

### JSON 데이터 분석

```python
await agent.run("""
api_response.json 파일에서:
1. 중첩된 JSON 구조 평탄화
2. DataFrame으로 변환
3. 주요 필드 통계 분석
""")
```

## 데이터 정제

### 결측값 처리

```python
await agent.run("""
customer_data.csv에서 결측값을 처리해줘:
1. 결측값이 있는 행/열 확인
2. 수치형 컬럼은 평균값으로 대체
3. 범주형 컬럼은 최빈값으로 대체
4. 정제된 데이터를 clean_customer_data.csv로 저장
""")
```

### 이상치 탐지 및 제거

```python
await agent.run("""
sensor_data.csv에서:
1. IQR 방법으로 이상치 탐지
2. 이상치 시각화 (박스플롯)
3. 이상치 제거 또는 대체
4. 정제 전후 비교 리포트 작성
""")
```

### 데이터 타입 변환

```python
await agent.run("""
transactions.csv에서:
1. 날짜 문자열을 datetime으로 변환
2. 가격 문자열을 숫자로 변환
3. 범주형 변수를 category 타입으로 변환
4. 메모리 사용량 최적화
""")
```

### 중복 데이터 처리

```python
await agent.run("""
users.csv에서:
1. 중복된 이메일 주소 찾기
2. 최신 레코드만 유지
3. 중복 제거 결과 리포트
""")
```

## 탐색적 데이터 분석 (EDA)

### 기술 통계

```python
await agent.run("""
sales_data.csv에 대해:
1. 기술 통계 (평균, 중앙값, 표준편차 등)
2. 분포 확인 (히스토그램)
3. 상관관계 분석 (상관계수 히트맵)
4. 분석 리포트 생성
""")
```

### 시계열 분석

```python
await agent.run("""
stock_prices.csv의 시계열 데이터를:
1. 날짜별 추세 시각화
2. 이동평균 계산 및 표시
3. 계절성 분석
4. 미래 가격 예측 (7일)
""")
```

### 그룹별 분석

```python
await agent.run("""
orders.csv에서 제품 카테고리별로:
1. 총 매출 합계
2. 평균 주문 금액
3. 주문 건수
4. 막대 차트로 시각화
""")
```

### 교차 분석

```python
await agent.run("""
survey_data.csv에서:
1. 연령대별 × 성별 × 선호도 교차 분석
2. 피벗 테이블 생성
3. 히트맵으로 시각화
""")
```

## 데이터 시각화

### 기본 차트

```python
await agent.run("""
monthly_sales.csv를 사용해서:
1. 월별 매출 꺾은선 그래프
2. 제품별 매출 막대 차트
3. 지역별 매출 파이 차트
모든 차트를 하나의 대시보드로 구성하고 dashboard.png로 저장
""")
```

### 고급 시각화

```python
await agent.run("""
customer_behavior.csv로:
1. 산점도 행렬 (scatter matrix)
2. 상관관계 히트맵
3. 박스플롯 (이상치 표시)
4. 바이올린 플롯 (분포 비교)
모든 차트에 한글 폰트 적용하고 visualization.png로 저장
""")
```

### 인터랙티브 차트

```python
await agent.run("""
plotly를 사용해서 인터랙티브 차트 생성:
1. 3D 산점도
2. 애니메이션 시계열 차트
3. 인터랙티브 대시보드
결과를 HTML 파일로 저장
""")
```

### 지리 정보 시각화

```python
await agent.run("""
store_locations.csv의 위치 데이터를:
1. 지도 위에 매장 위치 표시
2. 매출액에 따라 마커 크기 조정
3. 지역별 색상 구분
4. 인터랙티브 지도를 map.html로 저장
""")
```

## 통계 분석

### 가설 검정

```python
await agent.run("""
experiment_results.csv에서:
1. A/B 테스트 그룹 간 평균 비교
2. t-검정 수행
3. p-value 해석
4. 통계적 유의성 확인
결과를 리포트로 작성
""")
```

### 회귀 분석

```python
await agent.run("""
housing_data.csv를 사용해서:
1. 주택 가격 예측 모델 구축 (선형 회귀)
2. 모델 성능 평가 (R², RMSE)
3. 잔차 분석
4. 예측값 vs 실제값 시각화
""")
```

### 상관관계 분석

```python
await agent.run("""
variables.csv에서:
1. 피어슨 상관계수 계산
2. 스피어만 상관계수 계산
3. 상관관계 히트맵 생성
4. 유의미한 상관관계 리스트 작성
""")
```

## 머신러닝

### 분류 모델

```python
await agent.run("""
customer_churn.csv로 고객 이탈 예측 모델:
1. 데이터 전처리 및 피처 엔지니어링
2. 학습/테스트 데이터 분할
3. 랜덤 포레스트 모델 학습
4. 모델 성능 평가 (정확도, precision, recall, F1)
5. 중요 변수 시각화
""")
```

### 군집화

```python
await agent.run("""
customer_segments.csv로 고객 세분화:
1. K-means 클러스터링
2. 최적 클러스터 수 결정 (elbow method)
3. 클러스터별 특성 분석
4. 2D 시각화 (PCA 차원 축소)
""")
```

### 시계열 예측

```python
await agent.run("""
sales_history.csv로 매출 예측:
1. ARIMA 모델 구축
2. 향후 30일 매출 예측
3. 신뢰 구간 표시
4. 예측 결과 시각화
""")
```

## 대용량 데이터 처리

### 청크 단위 처리

```python
await agent.run("""
large_file.csv (5GB) 파일을 청크 단위로 처리:
1. 10만 행씩 나누어 읽기
2. 각 청크 필터링 및 변환
3. 결과를 하나로 병합
4. 처리 과정 진행률 표시
""")
```

### 메모리 최적화

```python
await agent.run("""
big_data.csv를 메모리 효율적으로 처리:
1. 데이터 타입 최적화 (int64 → int32 등)
2. 불필요한 컬럼 제거
3. 범주형 변수 category 타입으로 변환
4. 메모리 사용량 전후 비교
""")
```

### 병렬 처리

```python
await agent.run("""
여러 CSV 파일을 병렬로 처리:
1. data/ 디렉토리의 모든 CSV 파일 찾기
2. 각 파일을 병렬로 읽어서 처리
3. 결과를 하나의 DataFrame으로 병합
4. 최종 결과 저장
""")
```

## 리포팅

### 자동화된 리포트

```python
await agent.run("""
monthly_data.csv로 월간 리포트 생성:
1. 주요 지표 계산 (총 매출, 성장률 등)
2. 트렌드 차트 생성
3. 인사이트 및 권장사항 작성
4. PDF 리포트 생성
""")
```

### 대시보드

```python
await agent.run("""
실시간 대시보드 생성:
1. 주요 KPI 표시
2. 시각화 차트 (매출, 사용자, 전환율 등)
3. 필터 및 인터랙티브 요소 추가
4. HTML 대시보드로 저장
""")
```

### Excel 리포트

```python
await agent.run("""
분석 결과를 Excel 리포트로:
1. 여러 시트에 데이터 및 차트 배치
2. 조건부 서식 적용
3. 피벗 테이블 생성
4. 프로페셔널한 스타일 적용
5. analysis_report.xlsx로 저장
""")
```

## 모범 사례

### 1. 데이터 검증

```python
# ✅ 데이터 품질 확인
await agent.run("""
data.csv를 로드하기 전에:
1. 파일 존재 및 형식 확인
2. 예상 컬럼이 모두 있는지 확인
3. 데이터 타입이 올바른지 검증
4. 문제가 있으면 상세한 오류 리포트
""")
```

### 2. 재현 가능한 분석

```python
# ✅ 랜덤 시드 설정
await agent.run("""
머신러닝 분석시:
1. 랜덤 시드 고정 (random_state=42)
2. 데이터 분할 방법 문서화
3. 사용한 파라미터 기록
4. 결과 재현을 위한 정보 저장
""")
```

### 3. 에러 처리

```python
# ✅ 견고한 에러 처리
await agent.run("""
데이터 처리 중 오류 발생시:
1. 구체적인 오류 메시지 출력
2. 문제가 있는 행/열 표시
3. 가능한 해결 방법 제시
4. 처리 가능한 데이터만 계속 진행
""")
```

### 4. 성능 모니터링

```python
# ✅ 처리 시간 측정
await agent.run("""
대용량 데이터 처리시:
1. 각 단계별 소요 시간 측정
2. 메모리 사용량 모니터링
3. 병목 지점 파악
4. 최적화 가능 영역 제안
""")
```

## 실전 예제

### 전자상거래 매출 분석

```python
await agent.run("""
e-commerce 데이터 분석:

데이터 파일:
- orders.csv: 주문 내역
- products.csv: 제품 정보
- customers.csv: 고객 정보

분석 내용:
1. 월별 매출 트렌드
2. 베스트셀러 제품 TOP 10
3. 고객 세그먼트 분석
4. 재구매율 계산
5. 제품 추천 (연관 규칙 마이닝)

결과물:
- 시각화 차트 모음 (charts/)
- 분석 리포트 (report.pdf)
- 핵심 지표 대시보드 (dashboard.html)
""")
```

### 금융 데이터 분석

```python
await agent.run("""
주식 포트폴리오 분석:

데이터 파일:
- portfolio.csv: 보유 주식
- prices.csv: 일별 가격 데이터

분석 내용:
1. 포트폴리오 수익률 계산
2. 리스크 분석 (변동성, VaR)
3. 샤프 비율 계산
4. 상관관계 분석
5. 최적 포트폴리오 제안

결과물:
- 성과 리포트
- 리스크 분석 차트
- 포트폴리오 최적화 제안
""")
```

### 고객 행동 분석

```python
await agent.run("""
웹사이트 사용자 행동 분석:

데이터 파일:
- user_events.csv: 사용자 행동 로그
- user_profiles.csv: 사용자 프로필

분석 내용:
1. 사용자 이탈 분석 (churn analysis)
2. 전환 퍼널 분석
3. 코호트 분석
4. RFM 분석 (Recency, Frequency, Monetary)
5. 이탈 예측 모델

결과물:
- 사용자 세그먼트 리포트
- 이탈 예측 모델
- 액션 아이템 추천
""")
```

## 문제 해결

### 일반적인 문제

#### 1. 인코딩 오류

```python
# 문제: 한글이 깨짐
# 해결:
await agent.run("""
CSV 파일을 UTF-8 인코딩으로 읽어줘.
만약 오류가 나면 EUC-KR 또는 CP949로 시도해줘.
""")
```

#### 2. 메모리 부족

```python
# 문제: MemoryError
# 해결:
await agent.run("""
대용량 파일을 청크 단위로 처리:
- chunksize=10000으로 읽기
- 필요한 컬럼만 선택
- 데이터 타입 최적화
""")
```

#### 3. 느린 처리 속도

```python
# 해결:
await agent.run("""
성능 최적화:
1. 벡터화 연산 사용 (반복문 대신)
2. inplace=True 옵션 사용
3. 범주형 데이터는 category 타입
4. 필요시 Dask나 Vaex 사용
""")
```

## 다음 단계

데이터 분석에 대해 이해했다면:

- [브라우저 자동화](./browser-automation.mdx) - 웹에서 데이터 수집하기
- [파일 편집](./file-editing.mdx) - 분석 결과 파일로 저장하기
- [가이드: 데이터 파이프라인](../guides/data-pipeline.mdx) - 전체 데이터 워크플로우 구축
